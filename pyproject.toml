[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "ptoon"
version = "0.0.2-dev"
description = "Token-Oriented Object Notation - A Python implementation optimized for LLM token efficiency."
requires-python = ">=3.10"
readme = "README.md"
license = { text = "MIT" }
authors = [{ name = "TOON Contributors", email = "nalongkon1996@gmail.com" }]
keywords = ["llm", "token", "serialization", "encoding", "ai", "optimization"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Text Processing",
]
# Core library has no runtime dependencies - pure Python stdlib
dependencies = []

[project.urls]
Homepage = "https://github.com/Justar96/ptoon"
Documentation = "https://github.com/Justar96/ptoon#readme"
Repository = "https://github.com/Justar96/ptoon"
"Bug Tracker" = "https://github.com/Justar96/ptoon/issues"
Changelog = "https://github.com/Justar96/ptoon/blob/main/docs/changelog.rst"

# Note: CLI scripts removed in v0.0.2 - benchmarks are dev tools, run from source
# To run benchmarks: git clone repo and run `uv run python -m benchmarks`

[project.optional-dependencies]
# Development dependencies (testing, linting, type checking)
dev = [
    "pytest>=7.0.0,<9.0.0",
    "pytest-cov>=4.0.0,<7.0.0",
    "pytest-asyncio>=0.21.0,<1.0.0",
    "pytest-mock>=3.10.0,<4.0.0",
    "black>=24.0.0,<26.0.0",
    "ruff>=0.8.0,<1.0.0",
    "mypy>=1.0.0,<2.0.0",
    "build>=1.0.0,<2.0.0",
    "twine>=5.0.0,<6.0.0",
    "tiktoken>=0.5.0,<1.0.0",  # For token counting tests
]
# Basic benchmark dependencies (token efficiency, speed, memory)
benchmark = [
    "tiktoken>=0.5.0,<1.0.0",
    "faker>=20.0.0,<40.0.0",
    "tqdm>=4.65.0,<5.0.0",
]
# LLM accuracy benchmark dependencies (requires OpenAI API or Vertex AI)
llm-benchmark = [
    "openai>=1.0.0,<2.0.0",
    "google-cloud-aiplatform>=1.122.0,<2.0.0",
    "tiktoken>=0.5.0,<1.0.0",
    "tqdm>=4.65.0,<5.0.0",
    "python-dotenv>=1.0.0,<2.0.0",
]
# Example scripts dependencies
examples = [
    "openai>=1.0.0,<2.0.0",
    "tiktoken>=0.5.0,<1.0.0",
]
# Documentation dependencies
docs = [
    "sphinx>=7.0.0,<8.0.0",
    "furo>=2024.0.0,<2025.0.0",
    "sphinx-copybutton>=0.5.0,<1.0.0",
    "myst-parser>=2.0.0,<3.0.0",
    "tomli>=2.0.0,<3.0.0; python_version < '3.11'",
]
# Install all optional dependencies
all = [
    "pytest>=7.0.0,<9.0.0",
    "pytest-cov>=4.0.0,<7.0.0",
    "pytest-asyncio>=0.21.0,<1.0.0",
    "pytest-mock>=3.10.0,<4.0.0",
    "black>=24.0.0,<26.0.0",
    "ruff>=0.8.0,<1.0.0",
    "mypy>=1.0.0,<2.0.0",
    "build>=1.0.0,<2.0.0",
    "twine>=5.0.0,<6.0.0",
    "tiktoken>=0.5.0,<1.0.0",
    "faker>=20.0.0,<40.0.0",
    "tqdm>=4.65.0,<5.0.0",
    "openai>=1.0.0,<2.0.0",
    "python-dotenv>=1.0.0,<2.0.0",
    "sphinx>=7.0.0,<8.0.0",
    "furo>=2024.0.0,<2025.0.0",
    "sphinx-copybutton>=0.5.0,<1.0.0",
    "myst-parser>=2.0.0,<3.0.0",
    "tomli>=2.0.0,<3.0.0; python_version < '3.11'",
]

[tool.hatchling.build.targets.wheel]
packages = ["ptoon", "benchmarks"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = ["-v", "--strict-markers", "--tb=short", "-m", "not integration"]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests requiring API access (deselect with '-m \"not integration\"')",
]

[tool.coverage.run]
source = ["ptoon"]
omit = ["tests/*", "benchmarks/*"]
branch = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
    "@abstractmethod",
]

[tool.ruff]
target-version = "py310"
line-length = 120
indent-width = 4

[tool.ruff.lint]
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "N",    # pep8-naming
    "UP",   # pyupgrade
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "SIM",  # flake8-simplify
    "PTH",  # flake8-use-pathlib
]
ignore = [
    "E501",  # line too long (handled by formatter)
    "B008",  # function call in default argument
    "B904",  # raise from inside except without cause
]

[tool.ruff.lint.per-file-ignores]
"tests/**/*.py" = [
    "N802",  # function name should be lowercase (test_* functions)
]
"benchmarks/**/*.py" = [
    "T201",  # print statements allowed in benchmarks
]

[tool.ruff.lint.isort]
known-first-party = ["ptoon"]
force-single-line = false
lines-after-imports = 2

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
disallow_any_generics = false
check_untyped_defs = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
strict_equality = true

[[tool.mypy.overrides]]
module = "tests.*"
disallow_untyped_defs = false
check_untyped_defs = false

[[tool.mypy.overrides]]
module = [
    "openai.*",
    "tiktoken.*",
    "faker.*",
    "tqdm.*",
    "dotenv.*",
]
ignore_missing_imports = true

[tool.pyright]
pythonVersion = "3.10"
typeCheckingMode = "basic"
reportMissingImports = true
reportMissingTypeStubs = false
reportUnusedImport = true
reportUnusedVariable = true
reportDuplicateImport = true
include = ["ptoon"]
strictListInference = true
strictDictionaryInference = true
strictParameterNoneValue = true
exclude = [
    "tests",
    "benchmarks",
    "examples",
]
