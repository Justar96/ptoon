### LLM Accuracy Benchmark Results
Tested with **gpt-5-mini** across **10 questions**

```
JSON         ████████████████████  100.0% (10/10)
TOON         ████████████████████  100.0% (10/10)
```

**Advantage:** TOON achieves **100.0% accuracy** (vs JSON's 100.0%) while using **48.4% fewer tokens**.

| Format | Accuracy | Avg Tokens | Avg Latency (ms) | Input Tokens | Output Tokens | Est. Cost |
|--------|----------|------------|------------------|--------------|---------------|-----------|
| `JSON` | 100.0% | 11,082 | 3208.7 | 74,513 | 47 | $0.0936 |
| `TOON` | 100.0% | 5,716 | 3676.5 | 28,613 | 47 | $0.0362 |

*Costs based on Google Vertex AI pricing: $1.25 per 1M input tokens, $10.00 per 1M output tokens (cached: $0.125/1M). Estimates use regular pricing; actual costs may be ~40-60% lower with prompt caching.*

| Dataset | JSON Tokens | TOON Tokens | Savings | Bar |
|---------|-------------|-------------|---------|-----|
| Uniform employee records (TOON optimal format) | 5,992 | 2,162 | 63.9% | `███████░░░░░░░░░░░░░ 63.9% saved` |
| E-commerce orders with nested structures | 10,680 | 7,099 | 33.5% | `█████████████░░░░░░░ 33.5% saved` |
| Time-series analytics data | 10,969 | 4,499 | 59.0% | `████████░░░░░░░░░░░░ 59.0% saved` |
| Top 100 GitHub repositories | 16,688 | 9,106 | 45.4% | `███████████░░░░░░░░░ 45.4% saved` |

<details>
<summary><strong>View detailed breakdown by dataset</strong></summary>

#### Performance by Dataset

##### Uniform employee records (TOON optimal format)

| Format | Accuracy | Tokens | Correct/Total |
|--------|----------|--------|---------------|
| `JSON` | 100.0% | 5,992 | 10/10 |
| `TOON` | 100.0% | 2,162 | 10/10 |

##### E-commerce orders with nested structures

| Format | Accuracy | Tokens | Correct/Total |
|--------|----------|--------|---------------|

##### Time-series analytics data

| Format | Accuracy | Tokens | Correct/Total |
|--------|----------|--------|---------------|

##### Top 100 GitHub repositories

| Format | Accuracy | Tokens | Correct/Total |
|--------|----------|--------|---------------|

#### Methodology

- **Semantic validation**: LLM-as-judge validates responses semantically (not exact string matching).
- **Token counting**: Using `tiktoken` with `o200k_base` encoding (equivalent to gpt-tokenizer).
- **Question types**: 10 questions across field retrieval, aggregation, and filtering tasks.
- **Datasets**: Faker-generated datasets (seeded for reproducibility) + GitHub repositories.
- **Model**: gpt-5-mini
- **Dual API keys**: Separate OpenAI API keys used for JSON and TOON evaluations to enable independent tracking.

</details>